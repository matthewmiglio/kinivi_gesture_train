{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b5582fe",
   "metadata": {},
   "source": [
    "## Create Point History Dataset - Instructions\n",
    "1. Prepare a video of the hand gesture\n",
    "    -Ideally, the video contains only your target gesture. Cut the video to exclude moments before or after your dynamic gesture\n",
    "2. Use the final cell to specify your dataset_identifier, this gesture_id, this gesture_label, and this gesture's video_path\n",
    "3. Running the create_data_csv_given_videos_folder() script will use mediapipe hand tracking to infer keypoint positions, writing point locations and timestamps in batches of 16 with their respective gesture classification.\n",
    "4. Use \n",
    "\n",
    "        train-point-history-classifier\\isolated_gesture_sets\\label_changer.ipynb\n",
    "\n",
    "        train-point-history-classifier\\isolated_gesture_sets\\assembler.ipynb\n",
    "\n",
    "        train-point-history-classifier\\isolated_gesture_sets\\analysis.ipynb\n",
    "\n",
    "        train-point-history-classifier\\isolated_gesture_sets\\_set_cutter.ipynb\n",
    "\n",
    "    to create a full point-history dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import third-party modules\n",
    "import csv\n",
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "from collections import deque\n",
    "import cv2 as cv\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b413f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import runtime models\n",
    "from runtime_models.keypoint_classifier.keypoint_classifier import KeyPointClassifier\n",
    "from runtime_models.point_history_classifier.point_history_classifier import PointHistoryClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89cc25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tells mediapipe to use static image mode, or video stream mode (for temportal tracking of keypoints)\n",
    "USE_STATIC_IMAGE_MODE = False\n",
    "MIN_DETECTION_CONFIDENCE = 0.6\n",
    "MIN_TRACKING_CONFIDENCE = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64966973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_keypoint_classifier_labels():\n",
    "    with open(\n",
    "        \"runtime_models/keypoint_classifier/keypoint_classifier_label.csv\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "    ) as f:\n",
    "        keypoint_classifier_labels = csv.reader(f)\n",
    "        keypoint_classifier_labels = [row[0] for row in keypoint_classifier_labels]\n",
    "        return keypoint_classifier_labels\n",
    "\n",
    "\n",
    "def read_point_history_classifier_labels():\n",
    "    with open(\n",
    "        \"runtime_models/point_history_classifier/point_history_classifier_label.csv\",\n",
    "        encoding=\"utf-8-sig\",\n",
    "    ) as f:\n",
    "        point_history_classifier_labels = csv.reader(f)\n",
    "        point_history_classifier_labels = [\n",
    "            row[0] for row in point_history_classifier_labels\n",
    "        ]\n",
    "        return point_history_classifier_labels\n",
    "\n",
    "\n",
    "def avi_to_images(video_file):\n",
    "    images = []\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        images.append(image)\n",
    "\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "    return images\n",
    "\n",
    "\n",
    "def calc_landmark_list(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "    def normalize_(n):\n",
    "        return n / max_value\n",
    "\n",
    "    temp_landmark_list = list(map(normalize_, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "\n",
    "def pre_process_point_history(image, point_history):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    temp_point_history = copy.deepcopy(point_history)\n",
    "\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, point in enumerate(temp_point_history):\n",
    "        if index == 0:\n",
    "            base_x, base_y = point[0], point[1]\n",
    "\n",
    "        temp_point_history[index][0] = (\n",
    "            temp_point_history[index][0] - base_x\n",
    "        ) / image_width\n",
    "        temp_point_history[index][1] = (\n",
    "            temp_point_history[index][1] - base_y\n",
    "        ) / image_height\n",
    "\n",
    "    temp_point_history = list(itertools.chain.from_iterable(temp_point_history))\n",
    "\n",
    "    return temp_point_history\n",
    "\n",
    "\n",
    "def count_zeros(list):\n",
    "    zero_count = 0\n",
    "    zero_examples = [0, 0.0, \"0\", \"0.0\", [0.0, 0.0]]\n",
    "    for i in list:\n",
    "        if i in zero_examples:\n",
    "            zero_count += 1\n",
    "    return zero_count\n",
    "\n",
    "\n",
    "def log(\n",
    "    point_history_csv_path,\n",
    "    gesture_number,\n",
    "    point_history,\n",
    "):\n",
    "    print_mode = True\n",
    "    write_mode = True\n",
    "    zero_count_max = 13\n",
    "    min_history_length = 16\n",
    "    print_errors = False\n",
    "    point_history_lenght_requirement = 32\n",
    "\n",
    "    if len(point_history) != point_history_lenght_requirement:\n",
    "        if print_errors:\n",
    "            print(\n",
    "                f\"Point history length is not equal to {point_history_lenght_requirement}: {len(point_history)}.\"\n",
    "            )\n",
    "        return\n",
    "\n",
    "    empty_count = count_zeros(point_history)\n",
    "    if empty_count > zero_count_max:\n",
    "        if print_errors:\n",
    "            print(f\"Too many empty points in {point_history}.\")\n",
    "        return\n",
    "\n",
    "    history_length = len(point_history)\n",
    "    if history_length < min_history_length:\n",
    "        if print_errors:\n",
    "            print(f\"History length is too short: {history_length}.\")\n",
    "        return\n",
    "\n",
    "    row = [gesture_number, *point_history]\n",
    "    if print_mode is True:\n",
    "        print(row)\n",
    "    if write_mode is True:\n",
    "        with open(point_history_csv_path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "def log_point_history_from_video_or_folder(\n",
    "    path, gesture_number=-1, dataset_identifier_string=\"NID\", gesture_name=\"NG\"\n",
    "):\n",
    "    \"\"\"\n",
    "    logging_mode:\n",
    "        0: No logging\n",
    "        1: Keypoint classifier logging\n",
    "        2: Point history classifier logging\n",
    "    gesture_number:\n",
    "        the number of the gesture that we're adding to the data file\n",
    "    \"\"\"\n",
    "    # point_history_csv_path = (\n",
    "    #                 f\"isolated_gesture_sets\\point_history_{dataset_identifier_string}_{gesture_name}_{gesture_number}.csv\"\n",
    "    #             )\n",
    "    point_history_csv_path = f\"isolated_gesture_sets\\point_history_{dataset_identifier_string}_{gesture_number}_{gesture_name}.csv\"\n",
    "\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(\n",
    "        static_image_mode=USE_STATIC_IMAGE_MODE,\n",
    "        max_num_hands=1,\n",
    "        min_detection_confidence=MIN_DETECTION_CONFIDENCE,\n",
    "        min_tracking_confidence=MIN_TRACKING_CONFIDENCE,\n",
    "    )\n",
    "    keypoint_classifier = KeyPointClassifier()\n",
    "    point_history_classifier = PointHistoryClassifier()\n",
    "    history_length = 16\n",
    "    point_history = deque(maxlen=history_length)\n",
    "    finger_gesture_history = deque(maxlen=history_length)\n",
    "\n",
    "    # load the images depending if folder or video file\n",
    "    if os.path.isdir(path):\n",
    "        print(f\"Processing this path as a folder: {path}\")\n",
    "        image_files = sorted([f for f in os.listdir(path)])\n",
    "        image_paths = [os.path.join(path, image_file) for image_file in image_files]\n",
    "        images = [cv.imread(image_path) for image_path in image_paths]\n",
    "    elif os.path.isfile(path):\n",
    "        print(f\"Processing this path as a video file: {path}\")\n",
    "        images = avi_to_images(path)\n",
    "    else:\n",
    "        print(f\"WARNING! This path is neither a folder nor a file: {path}\")\n",
    "        return\n",
    "\n",
    "    # play video once\n",
    "    for image in images:\n",
    "        key = cv.waitKey(10)\n",
    "        if key == 27:  # ESC\n",
    "            return\n",
    "\n",
    "        image = cv.flip(image, 1)\n",
    "        debug_image = copy.deepcopy(image)\n",
    "\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks, handedness in zip(\n",
    "                results.multi_hand_landmarks, results.multi_handedness\n",
    "            ):\n",
    "                landmark_list = calc_landmark_list(debug_image, hand_landmarks)\n",
    "\n",
    "                pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "                pre_processed_point_history_list = pre_process_point_history(\n",
    "                    debug_image, point_history\n",
    "                )\n",
    "\n",
    "                log(\n",
    "                    point_history_csv_path,\n",
    "                    gesture_number,\n",
    "                    pre_processed_point_history_list,\n",
    "                )\n",
    "\n",
    "                hand_sign_id = keypoint_classifier(pre_processed_landmark_list)\n",
    "\n",
    "                if hand_sign_id == 2:\n",
    "                    point_history.append(landmark_list[8])\n",
    "                else:\n",
    "                    point_history.append([0, 0])\n",
    "\n",
    "                finger_gesture_id = 0\n",
    "                point_history_len = len(pre_processed_point_history_list)\n",
    "                if point_history_len == (history_length * 2):\n",
    "                    finger_gesture_id = point_history_classifier(\n",
    "                        pre_processed_point_history_list\n",
    "                    )\n",
    "\n",
    "                finger_gesture_history.append(finger_gesture_id)\n",
    "        else:\n",
    "            point_history.append([0, 0])\n",
    "\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_csv_given_videos_folder(\n",
    "    folder,\n",
    "    gesture_number,\n",
    "    dataset_identifier,\n",
    "    gesture_name,\n",
    "):\n",
    "    video_files = [os.path.join(folder, f) for f in os.listdir(folder)]\n",
    "    print(f\"This video contains {len(video_files)} files\")\n",
    "    for video_file in video_files:\n",
    "        log_point_history_from_video_or_folder(\n",
    "            video_file,\n",
    "            gesture_number=gesture_number,\n",
    "            dataset_identifier_string=dataset_identifier,\n",
    "            gesture_name=gesture_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d94c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_identifier = \"big_dataset_2025\"\n",
    "gesture_id = 1\n",
    "gesture_label = \"erratic\"\n",
    "video_path = r\"C:\\my_files\\data\\matt_gesture\\labeled_videos\\erratic\"\n",
    "\n",
    "create_data_csv_given_videos_folder(\n",
    "    video_path, gesture_id, dataset_identifier, gesture_label\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
